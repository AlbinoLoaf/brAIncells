{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b654b384-ee4e-4223-a48f-ffffb7eb1d6e",
   "metadata": {},
   "source": [
    "## Initial notebook for project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23748e0-ee24-4a9b-8cab-90b0d02be953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and set up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torcheeg.io.eeg_signal import EEGSignalIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Path to dir with data (remember the last '/')\n",
    "path = \"../data/\"\n",
    "\n",
    "## Establish connection to datafile\n",
    "IO = EEGSignalIO(io_path=str(path), io_mode='lmdb')\n",
    "## Read metadata dataframeimports\n",
    "metadata = pd.read_csv(path + 'sample_metadata.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b99ce4-2205-4911-8f56-acb6dfde1e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsamples: 5184  -  nchannels: 22  -  t: 800\n"
     ]
    }
   ],
   "source": [
    "# Verifying connextion to data\n",
    "idxs = np.arange(len(metadata))\n",
    "\n",
    "X = torch.FloatTensor(np.array([IO.read_eeg(str(i)) for i in idxs]))\n",
    "print(f\"nsamples: {X.shape[0]}  -  nchannels: {X.shape[1]}  -  t: {X.shape[2]}\")\n",
    "\n",
    "y = torch.tensor(metadata[\"value\"].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a467f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X train: torch.Size([3110, 22, 800])\n",
      "shape of X val: torch.Size([1037, 22, 800])\n",
      "shape of X test: torch.Size([1037, 22, 800])\n",
      "shape of y train: torch.Size([3110])\n",
      "shape of y val: torch.Size([1037])\n",
      "shape of y test: torch.Size([1037])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"shape of X train: {X_train.shape}\")\n",
    "print(f\"shape of X val: {X_val.shape}\")\n",
    "print(f\"shape of X test: {X_test.shape}\")\n",
    "\n",
    "print(f\"shape of y train: {y_train.shape}\")\n",
    "print(f\"shape of y val: {y_val.shape}\")\n",
    "print(f\"shape of y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82f7414-d46e-4a28-a595-1c3b6a652833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up of matrixies \n",
    "#number of samples, channels, and timesteps\n",
    "nsamples_train, nchannels_train, t = X_train.shape\n",
    "nsamples_val, nchannels_val, t = X_val.shape\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "adj_matrix_train = torch.eye(nchannels_train)\n",
    "adj_matrix_val = torch.eye(nchannels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8934a349-39a6-444a-bdab-fcc24bdc9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = torch.matmul(adj, x)  \n",
    "        x = torch.matmul(x, self.weight) + self.bias  \n",
    "        return torch.relu(x)\n",
    "\n",
    "class EEG_GNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, nclasses, nchannels):\n",
    "        super(EEG_GNN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_features, hidden_dim)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(nchannels) \n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(nchannels) \n",
    "        self.conv3 = GraphConv(hidden_dim, nclasses)  \n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.conv1(x, adj)\n",
    "        x = self.batch_norm1(x)  \n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, adj)\n",
    "        x = self.batch_norm2(x)  \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, adj)  \n",
    "        x = x.mean(dim=1)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e20f2ba-732c-4d19-9e0e-0fd4848cbda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 22])\n",
      "<class 'torch.Tensor'>\n",
      "3110\n",
      "torch.Size([22, 22])\n",
      "<class 'torch.Tensor'>\n",
      "1037\n"
     ]
    }
   ],
   "source": [
    "print(adj_matrix_train.shape)\n",
    "print(type(adj_matrix_train))\n",
    "print(nsamples_train)\n",
    "\n",
    "print(adj_matrix_val.shape)\n",
    "print(type(adj_matrix_val))\n",
    "print(nsamples_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abee87ab-7aaa-4965-9ffd-b2a9a1c252b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_by_corr(data, nsamples, threshold=0.5):\n",
    "\n",
    "    # Compute Pearson correlation between channels\n",
    "    tmp_lst=[]\n",
    "    \n",
    "    for i in range(nsamples): \n",
    "        correlation_matrix = np.corrcoef(data[i])\n",
    "        tmp_lst.append((correlation_matrix > threshold).astype(np.float32))\n",
    "        \n",
    "    # Convert correlation to adjacency matrix\n",
    "    adj_mat = torch.from_numpy(np.array(tmp_lst))\n",
    "    \n",
    "    return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c0f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGNN():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def train_model(self, model, train_loader, val_loader, adjacency_matrix, learning_rate=0.0005, epochs=500, prints=True):\n",
    "        model = model.to(self.device)\n",
    "        adjacency_matrix = adjacency_matrix.to(self.device)  # Move adjacency to GPU if available\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        highest_train_accuracy = 0.0\n",
    "        \n",
    "        losses_train = []; losses_val = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0; running_loss_val = 0.0\n",
    "            correct = 0; correct_val = 0\n",
    "            total = 0; total_val = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs, adjacency_matrix)  # Forward pass\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_accuracy = correct/total\n",
    "            losses_train.append(epoch_loss)\n",
    "            \n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs, adjacency_matrix)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss_val += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                \n",
    "            epoch_loss_val = running_loss_val / len(val_loader.dataset)\n",
    "            epoch_accuracy_val = correct_val/total_val\n",
    "            losses_val.append(epoch_loss_val)\n",
    "                \n",
    "            if epoch_accuracy > highest_train_accuracy:\n",
    "                highest_train_accuracy = epoch_accuracy\n",
    "\n",
    "            if prints:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Train loss: {epoch_loss:.4f}, Train acc: {(epoch_accuracy*100):.2f}%\" +\n",
    "                     f\"| Val loss: {epoch_loss_val:.4f}, Val acc: {(epoch_accuracy_val*100):.2f}%\")\n",
    "\n",
    "        print(f\"Highest Train Accuracy {(highest_train_accuracy*100):.2f}\")\n",
    "        torch.save(model.state_dict(), 'eeg_gnn.pth')\n",
    "        \n",
    "        losses = [losses_train, losses_val]\n",
    "\n",
    "        return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4273af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train loss: 3.0868, Train acc: 16.72%| Val loss: 2.8919, Val acc: 16.39%\n",
      "Epoch 2/20, Train loss: 2.6281, Train acc: 19.20%| Val loss: 2.5702, Val acc: 17.36%\n",
      "Epoch 3/20, Train loss: 2.3599, Train acc: 21.41%| Val loss: 2.3630, Val acc: 18.42%\n",
      "Epoch 4/20, Train loss: 2.1719, Train acc: 22.64%| Val loss: 2.2250, Val acc: 19.19%\n",
      "Epoch 5/20, Train loss: 2.0324, Train acc: 23.38%| Val loss: 2.1025, Val acc: 19.48%\n",
      "Epoch 6/20, Train loss: 1.9274, Train acc: 24.95%| Val loss: 2.0167, Val acc: 19.38%\n",
      "Epoch 7/20, Train loss: 1.8470, Train acc: 25.69%| Val loss: 1.9496, Val acc: 19.58%\n",
      "Epoch 8/20, Train loss: 1.7823, Train acc: 25.98%| Val loss: 1.8932, Val acc: 20.25%\n",
      "Epoch 9/20, Train loss: 1.7348, Train acc: 26.56%| Val loss: 1.8464, Val acc: 19.86%\n",
      "Epoch 10/20, Train loss: 1.6958, Train acc: 26.43%| Val loss: 1.8130, Val acc: 19.67%\n",
      "Epoch 11/20, Train loss: 1.6678, Train acc: 27.04%| Val loss: 1.7913, Val acc: 19.96%\n",
      "Epoch 12/20, Train loss: 1.6454, Train acc: 27.49%| Val loss: 1.7734, Val acc: 20.73%\n",
      "Epoch 13/20, Train loss: 1.6266, Train acc: 27.49%| Val loss: 1.7525, Val acc: 20.64%\n",
      "Epoch 14/20, Train loss: 1.6118, Train acc: 27.81%| Val loss: 1.7412, Val acc: 20.73%\n",
      "Epoch 15/20, Train loss: 1.5998, Train acc: 28.46%| Val loss: 1.7280, Val acc: 20.64%\n",
      "Epoch 16/20, Train loss: 1.5872, Train acc: 28.23%| Val loss: 1.7209, Val acc: 20.73%\n",
      "Epoch 17/20, Train loss: 1.5789, Train acc: 29.10%| Val loss: 1.7147, Val acc: 21.22%\n",
      "Epoch 18/20, Train loss: 1.5689, Train acc: 29.61%| Val loss: 1.7075, Val acc: 21.31%\n",
      "Epoch 19/20, Train loss: 1.5623, Train acc: 29.84%| Val loss: 1.7059, Val acc: 21.22%\n",
      "Epoch 20/20, Train loss: 1.5547, Train acc: 30.19%| Val loss: 1.7052, Val acc: 21.31%\n",
      "Highest Train Accuracy 30.19\n"
     ]
    }
   ],
   "source": [
    "nclasses = y.max().item() + 1 \n",
    "model = EEG_GNN(in_features=t, hidden_dim=32, nclasses=nclasses, nchannels=nchannels_train)\n",
    "\n",
    "trainer = TrainGNN()\n",
    "trained_model, losses = trainer.train_model(model, train_loader, val_loader, adj_matrix_train, epochs=20, prints=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
